{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN42VZhp3-1I",
        "outputId": "59e3dc52-9dc2-4bf5-a92d-e79dfda64d50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing matrix_mul.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile matrix_mul.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 16  // Matrix size (N x N)\n",
        "\n",
        "// CUDA kernel for matrix multiplication\n",
        "__global__ void matrixMulKernel(float *A, float *B, float *C, int n) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;  // Row index of C\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;  // Column index of C\n",
        "\n",
        "    if (row < n && col < n) {\n",
        "        float sum = 0.0f;\n",
        "        for (int k = 0; k < n; ++k) {\n",
        "            sum += A[row * n + k] * B[k * n + col];\n",
        "        }\n",
        "        C[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Host code\n",
        "int main() {\n",
        "    int size = N * N * sizeof(float);\n",
        "    float *h_A = (float *)malloc(size);\n",
        "    float *h_B = (float *)malloc(size);\n",
        "    float *h_C = (float *)malloc(size);\n",
        "\n",
        "    // Initialize input matrices\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = 1.0f;\n",
        "        h_B[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void **)&d_A, size);\n",
        "    cudaMalloc((void **)&d_B, size);\n",
        "    cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Kernel launch config\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 blocksPerGrid((N + 15) / 16, (N + 15) / 16);\n",
        "    matrixMulKernel<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print result (top-left 4x4 block)\n",
        "    printf(\"Top-left 4x4 result matrix:\\n\");\n",
        "    for (int i = 0; i < 4; i++) {\n",
        "        for (int j = 0; j < 4; j++) {\n",
        "            printf(\"%.1f \", h_C[i * N + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VRetp2UI4RXg"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 matrix_mul.cu -o matrix_mul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s7Cx8-O4W_h",
        "outputId": "daf7f0dd-e5d6-4f92-f3a2-4dbd05579181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-left 4x4 result matrix:\n",
            "32.0 32.0 32.0 32.0 \n",
            "32.0 32.0 32.0 32.0 \n",
            "32.0 32.0 32.0 32.0 \n",
            "32.0 32.0 32.0 32.0 \n"
          ]
        }
      ],
      "source": [
        "!./matrix_mul"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}